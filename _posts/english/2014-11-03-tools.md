---
title: Tools
type: pages
---

## Tools

Doing language documentation in the modern times is always something very technical. The recording equipments are growing more and more sophisticated. The data we collect is not anymore individual audio files which we can just start transcribing on the field, but often multiple audio and video files from which each session builds have to be cut, edited and synchronized before one actually can start working with the data. This is in itself a very complicated process into which many important decicions are deeply connected. What to cut away? When to split a session? What is the goal: do we want to have raw data constellations from which we transcribe the relevant pieces, or should we split different parts into their own subsessions and transcribe those? The first solution would be more "realistic" in a way that then we are still all the time waist down in the raw data itself. However, the second solution would lead to much more usable and compact datasets. These decicions are down while we edit the sessions and they should be made very explicit.

However, the place to make them explicit is metadata. It seems to be the case that at the moment we have very few actually working solutions for maintaining complex metadata. There are editors like Arbil, but I think you don't really want to have hundreds and informants and sessions managed in that environment. CMDI is coming, but there aren't that many good introductions how to set it up.

The approach taken in Freiburg Research Group in Saami Studies has been to manage the metadata in our own structures but to treat IMDI (and in future CMDI) as export formats. We have often used FileMaker Pro, but we have been thinking about starting to use shallow and easily modified XML which we would convert for archiving into more complex IMDI and CMDI structures. The XSLT stylesheets that are used in this can be seen as tools also useful for more linguists.

For further analysis of the data we have often been using R. It is ongoing work to tie different scripts into functions and packages that could be more easily shared. As an example, parsing ELAN files to R is very common task and makes it possible to analyse and visualize data in many ways very easily. 